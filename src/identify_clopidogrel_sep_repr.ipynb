{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clopidogrel-Stroke Cohort - Ischemic only\n",
    "(Not derived from the stroke cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folder import StandardFolder\n",
    "from polars_utils import *\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please correct me if I'm wrong / Suggest other ICD10s to add https://icd.who.int/browse10/2016/en#/I60-I69**\n",
    "\n",
    "- Clopidogrel (P2Y12 inhibitor) inhibits platelet aggregation.\n",
    "\n",
    "- Clopidogrel is mainly converted into its active metabolite through CYP2C19.\n",
    "\n",
    "This study aims to look at patients who have CYP2C19 polymorphism and their possible complications.\n",
    "\n",
    "- Poor Metabolisers\n",
    "    - I63: Ischemic stroke\n",
    "\n",
    "**Including TIA**\n",
    "- G45: TIA\n",
    "\n",
    "**Exclude OACs (DOACs, Warfarin)**\n",
    "\n",
    "Ward mapping: https://docs.google.com/spreadsheets/d/1qzxQRRRC0Vs576MvMdiJMfCCxkfvwZlQpzI1Ap9r3fQ/edit#gid=440115548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme not included.\n"
     ]
    }
   ],
   "source": [
    "target_icds = ['I63', 'G45']\n",
    "\n",
    "warehouse_folder = StandardFolder(folder='D:/Datalake/Data/20231231_fu_nc')\n",
    "\n",
    "admission_visit_cols = ['ENC_HN', 'D001KEY', 'D108KEY']\n",
    "stroke_unit = 'MDJ1' # in admissions\n",
    "emergency_department = 'OER101' # in visits\n",
    "\n",
    "dx_cols = ['ENC_HN', 'D001KEY', 'D035KEY', 'D108KEY', 'D195KEY'] # Primary diagnosis is when D195KEY is \"1\"\n",
    "sample_file = pl.read_parquet(list(warehouse_folder.dx.iterdir())[-1])\n",
    "assert {stroke_unit, emergency_department}.issubset(set([x.strip(' ') for x in sample_file['D108KEY'].unique() if x ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oac_df = pl.read_csv('../std/meds_AF.csv')\n",
    "# oac_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClopidogrelStrokeIdentify(StandardFolder):\n",
    "    def __init__(\n",
    "            self, \n",
    "            folder: str = 'D:/Datalake/Data/20231231_fu_nc', \n",
    "            export_folder: str = 'D:/Prut/Warehouses/output/Dec23/n/Clopidogrel',\n",
    "            select_dx: list[str] = target_icds, \n",
    "            select_dept: list[str] = [emergency_department, stroke_unit],\n",
    "            streaming: bool = True\n",
    "            ) -> None:\n",
    "        super().__init__(folder)\n",
    "\n",
    "        self.streaming = streaming\n",
    "        self.folder = Path(folder)\n",
    "        self.export_folder = Path(export_folder)\n",
    "        self.select_dx = select_dx\n",
    "        self.select_dx_re = '^' + '|^'.join(self.select_dx)\n",
    "        self.clopidogrel = pl.read_csv('../std/clopidogrel_med_code.csv').to_series(0).to_list() # ['PLAG-T-', 'CLAP-T-', 'COPL-T-', 'CLOD-T-', 'PLAP-T-', 'PLAP-T1', 'PLAV-T-']\n",
    "        self.ticagrelor = ['BRIL-T-',]\n",
    "        self.cilostazol = ['CIBZ-T-', 'CILO-T-', 'PLSR-C-', 'PLET-W-', 'PLET1T-', 'PLET-T-']\n",
    "        self.oac = pl.read_csv('../std/meds_AF.csv')['CODE'].to_list()\n",
    "        self.select_dept = select_dept\n",
    "        self.primary_dx = '1'\n",
    "        self.has_oac = []\n",
    "        self.ran_all = False\n",
    "        self.n_list = []\n",
    "\n",
    "\n",
    "    def get_dx(self):\n",
    "        folder_path = self.dx\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = (\n",
    "                scan_file(path)\n",
    "                .select(pl.col(['ENC_HN', 'D001KEY', 'D035KEY', 'D108KEY', 'D195KEY']))\n",
    "                .filter(pl.col('D035KEY').str.contains(self.select_dx_re))\n",
    "                .filter(pl.col('D108KEY').is_in(self.select_dept))\n",
    "                .filter(pl.col('D195KEY') == self.primary_dx)\n",
    "                .pipe(parse_dates, 'D001KEY')\n",
    "            )\n",
    "            # file = file.group_by(pl.col(['ENC_HN', 'D001KEY'])).agg(pl.col('D035KEY')).with_columns(pl.col('D035KEY').list.unique().list.sort().list.join(', '))\n",
    "            to_concat.append(file.collect(streaming=self.streaming))\n",
    "        self.dx_df = pl.concat(to_concat).unique()\n",
    "\n",
    "    def get_meds(self):\n",
    "        folder_path = self.bill\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = scan_file(path)\n",
    "            # Deal with alternative file structures\n",
    "            if {'PER_DATE_2', 'SERVICE_ID', 'CAL_SER_AMT'}.issubset(file.columns):\n",
    "                file = file.rename({'PER_DATE_2': 'D001KEY', 'SERVICE_ID': 'D033KEY', 'CAL_SER_AMT': 'M1022'})\n",
    "            file = (\n",
    "                file\n",
    "                .select(pl.col(['ENC_HN', 'D001KEY', 'D033KEY', 'M1022']))\n",
    "                .pipe(parse_dates, 'D001KEY')\n",
    "            )\n",
    "            # Store people who have ever recived an OAC\n",
    "            self.has_oac.extend(file.filter(pl.col('D033KEY').is_in(self.oac)).select('ENC_HN').unique().collect().to_series().to_list())\n",
    "\n",
    "            # Select clopidogrel, ticagrelor and cilostazol\n",
    "            file = file.filter(pl.col('D033KEY').is_in(self.clopidogrel + self.ticagrelor + self.cilostazol))\n",
    "\n",
    "            to_concat.append(file.collect(streaming=self.streaming))\n",
    "\n",
    "        self.meds_df = pl.concat(to_concat)\n",
    "\n",
    "        # pivot\n",
    "        # self.meds_df = self.meds_df.pivot(index=['ENC_HN', 'D001KEY'], values='M1022', columns='D033KEY', aggregate_function='max').unique()\n",
    "\n",
    "    def get_demo(self):\n",
    "        folder_path = self.demo\n",
    "        cols = ['ENC_HN', 'D020AT3', 'H2L1KEY']\n",
    "        new_col_names = ['ENC_HN', 'DOB', 'Sex']\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = scan_file(path)\n",
    "            if set(cols).issubset(set(file.columns)):\n",
    "                file = file.select(cols).collect(streaming=self.streaming).pipe(parse_dates, 'D020AT3') # New bug: only works in dataframes, so must collect first\n",
    "                to_concat.append(file)\n",
    "        self.demo_df = pl.concat(to_concat).unique()\n",
    "        self.demo_df = self.demo_df.rename(dict(zip(cols, new_col_names)))\n",
    "\n",
    "    def get_deaths(self):\n",
    "        folder_path = self.deaths\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = (\n",
    "                scan_file(path)\n",
    "                .select(pl.col('ENC_HN', 'D001KEY')).pipe(parse_dates, 'D001KEY').rename({'D001KEY': 'Death_date'})\n",
    "            )\n",
    "            to_concat.append(file.collect(streaming=self.streaming))\n",
    "        self.deaths_df = pl.concat(to_concat).unique()\n",
    "\n",
    "    def run_all(self):\n",
    "        self.get_dx()\n",
    "        print('dx')\n",
    "        # self.get_demo()\n",
    "        # print('demo')\n",
    "        self.get_meds()\n",
    "        print('meds')\n",
    "        self.get_deaths()\n",
    "        print('deaths')\n",
    "        \n",
    "        self.ran_all = True\n",
    "\n",
    "    def merge(self):\n",
    "        if not self.ran_all:\n",
    "            raise Exception('Please run all first.')\n",
    "        \n",
    "        self.merged_df = (\n",
    "            self.dx_df\n",
    "            # .join(self.demo_df, on=['ENC_HN'], how='left')\n",
    "            .join(self.meds_df, on=['ENC_HN', 'D001KEY'], how='left') # changed to left 28-05-2024\n",
    "            .join(self.deaths_df, on=['ENC_HN'], how='outer_coalesce')\n",
    "            .unique()\n",
    "            \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme not included.\n",
      "dx\n",
      "meds\n",
      "deaths\n"
     ]
    }
   ],
   "source": [
    "s = ClopidogrelStrokeIdentify()\n",
    "s.run_all()\n",
    "s.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following numbers are valid for data between 2010-2023.\n",
    "\n",
    "A flowchart will follow later after your initial comments and my adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of **patients** with a **primary diagnosis** of _stroke_, from **visits** to the **ER** or **admissions** to the **stroke unit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17208\n"
     ]
    }
   ],
   "source": [
    "print(s.merged_df['ENC_HN'].n_unique())\n",
    "# s.dx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of **patients** that have **never received an OAC** with a **primary diagnosis** of _stroke_, from **visits** to the **ER** or **admissions** to the **stroke unit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14443\n"
     ]
    }
   ],
   "source": [
    "df_no_oac = s.merged_df.filter(~pl.col('ENC_HN').is_in(s.has_oac))\n",
    "print(df_no_oac['ENC_HN'].n_unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of **patients** with **readmissions**, as defined as more than one visit of primarily diagnosed stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "readmission_hn = df_no_oac.select(['ENC_HN', 'D001KEY']).unique().group_by('ENC_HN').len().filter(pl.col('len') > 1)['ENC_HN']\n",
    "print(len(readmission_hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clopidogrel, ticagrelor, cilostazol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clopidogrel, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clopidogrel_df = (\n",
    "    df_no_oac\n",
    "    .filter(pl.col('D033KEY').is_in(s.clopidogrel))\n",
    ")\n",
    "clopidogrel_df['ENC_HN'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clopidogrel, recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(clopidogrel_df['ENC_HN']) & set(readmission_hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticagrelor, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticagrelor_df = (\n",
    "    df_no_oac\n",
    "    .filter(pl.col('D033KEY').is_in(s.ticagrelor))\n",
    ")\n",
    "ticagrelor_df['ENC_HN'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ticagrelor, recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(ticagrelor_df['ENC_HN']) & set(readmission_hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cilostazol, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cilostazol_df = (\n",
    "    df_no_oac\n",
    "    .filter(pl.col('D033KEY').is_in(s.cilostazol))\n",
    ")\n",
    "cilostazol_df['ENC_HN'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cilostazol, recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cilostazol_df['ENC_HN']) & set(readmission_hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_oac.filter(pl.col('ENC_HN').is_in(readmission_hn))['ENC_HN'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deaths in readmissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_oac.filter(pl.col('ENC_HN').is_in(readmission_hn)).filter(pl.col('Death_date').is_not_null())['ENC_HN'].n_unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of ICD-10 of readmission (I63 is ischemic stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ICD10</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;G45&quot;</td><td>262</td></tr><tr><td>&quot;I63&quot;</td><td>361</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬───────┐\n",
       "│ ICD10 ┆ count │\n",
       "│ ---   ┆ ---   │\n",
       "│ str   ┆ u32   │\n",
       "╞═══════╪═══════╡\n",
       "│ G45   ┆ 262   │\n",
       "│ I63   ┆ 361   │\n",
       "└───────┴───────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_oac.filter(pl.col('ENC_HN').is_in(readmission_hn)).with_columns(pl.col('D035KEY').str.slice(0, 3).alias('ICD10')).select(['ENC_HN', 'ICD10']).unique()['ICD10'].value_counts().sort('ICD10')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
