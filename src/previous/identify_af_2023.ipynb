{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(prev_hn) = 21989\n"
     ]
    }
   ],
   "source": [
    "from folder import StandardFolder\n",
    "from polars_utils import *\n",
    "\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# NEXT: add 2005-2009 then exclude later?\n",
    "prev_hn = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/AF/AF_201001_202306.csv').to_series().to_list()\n",
    "ecg_holter_hn = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/AF/af_for_aj_eak_180124.csv')\n",
    "print(f'{len(prev_hn) = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFIdentify(StandardFolder):\n",
    "    def __init__(self, folder: str, streaming: bool = True) -> None:\n",
    "        super().__init__(folder)\n",
    "        self.streaming = streaming\n",
    "        self.export_folder = Path('../output/Dec23/wh/complete')\n",
    "        self.select_dx = ['I48']\n",
    "        self.select_dx_re = '^' + '|^'.join(self.select_dx)\n",
    "        self.meds_to_select = pl.read_csv('../std/meds_AF.csv')\n",
    "        # self.prev_hn = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/Stroke/stroke_n_updatedSep2023_28112023.csv').to_series().to_list()\n",
    "        self.ran_all = False\n",
    "\n",
    "    def get_dx(self, select: list = None):\n",
    "        folder_path = self.dx\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = (\n",
    "                scan_file(path)\n",
    "                .select(pl.col(['ENC_HN', 'D001KEY', 'D035KEY']))\n",
    "                .pipe(parse_dates, 'D001KEY')\n",
    "            )\n",
    "            if select is not None:\n",
    "                file = file.filter(pl.col('D035KEY').str.contains(self.select_dx_re))\n",
    "            file = file.group_by(pl.col(['ENC_HN', 'D001KEY'])).agg(pl.col('D035KEY')).with_columns(pl.col('D035KEY').list.unique().list.sort().list.join(', '))\n",
    "            to_concat.append(file.collect(streaming=self.streaming))\n",
    "        self.dx_df = pl.concat(to_concat).unique()\n",
    "\n",
    "\n",
    "    def get_demo(self):\n",
    "        folder_path = self.demo\n",
    "        cols = ['ENC_HN', 'D020AT3', 'H2L1KEY', 'H6L1KEY', 'H6L1DES']\n",
    "        new_col_names = ['ENC_HN', 'DOB', 'Sex', 'Province_ID', 'Province_Thai']\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = scan_file(path)\n",
    "            if set(cols).issubset(set(file.columns)):\n",
    "                file = file.select(cols).collect(streaming=self.streaming).pipe(parse_dates, 'D020AT3') # New bug: only works in dataframes, so must collect first\n",
    "                to_concat.append(file)\n",
    "        self.demo_df = pl.concat(to_concat).unique()\n",
    "        self.demo_df = self.demo_df.rename(dict(zip(cols, new_col_names)))\n",
    "\n",
    "    def run_all(self):\n",
    "        self.get_dx(select=self.select_dx)\n",
    "        print('dx')\n",
    "        self.get_demo()\n",
    "        print('demo')\n",
    "        self.get_meds()\n",
    "        print('meds')\n",
    "        \n",
    "        self.ran_all = True\n",
    "\n",
    "    def merge(self):\n",
    "        if not self.ran_all:\n",
    "            raise Exception('Please run all first.')\n",
    "        \n",
    "        self.merged_df = (\n",
    "            self.dx_df\n",
    "            .join(self.demo_df, on=['ENC_HN'], how='left')\n",
    "            .join(self.meds_df, on=['ENC_HN', 'D001KEY'], how='outer_coalesce')\n",
    "            .unique()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def get_meds(self):\n",
    "        folder_path = self.bill\n",
    "        select = self.meds_to_select.to_series().to_list()\n",
    "        to_concat = []\n",
    "        for path in folder_path.iterdir():\n",
    "            file = (\n",
    "                scan_file(path)\n",
    "                # .filter(pl.col('ENC_HN').is_in(self.hn_list))\n",
    "                )\n",
    "            if {'PER_DATE_2', 'SERVICE_ID', 'CAL_SER_AMT'}.issubset(file.columns):\n",
    "                file = file.rename({'PER_DATE_2': 'D001KEY', 'SERVICE_ID': 'D033KEY', 'CAL_SER_AMT': 'M1022'})\n",
    "            file = (\n",
    "                file\n",
    "                .select(pl.col(['ENC_HN', 'D001KEY', 'D033KEY', 'M1022']))\n",
    "                .pipe(parse_dates, 'D001KEY')\n",
    "            )\n",
    "            if select is not None:\n",
    "                file = file.filter(pl.col('D033KEY').is_in(select))\n",
    "\n",
    "            to_concat.append(file.collect(streaming=self.streaming))\n",
    "        \n",
    "        # pivot\n",
    "        self.meds_df = pl.concat(to_concat).pivot(index=['ENC_HN', 'D001KEY'], values='M1022', columns='D033KEY', aggregate_function='max').unique()\n",
    "\n",
    "        # rename\n",
    "        for k, v in zip(self.meds_to_select['CODE'], self.meds_to_select['dosed_name']):\n",
    "            if k in self.meds_df.columns:\n",
    "                self.meds_df = self.meds_df.rename({k:v})\n",
    "\n",
    "\n",
    "        # Remove previous\n",
    "            # .pipe(self.remove_previous_hn)\n",
    "            # .pipe(print_n)\n",
    "            # Clip dates\n",
    "            # .pipe(clip_dates, date_col='D001KEY', start_month=7, start_year=2023, end_month=12, end_year=2023)\n",
    "            # .pipe(print_n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme not included.\n",
      "dx\n",
      "demo\n",
      "meds\n"
     ]
    }
   ],
   "source": [
    "s = AFIdentify(folder='D:/Datalake/Data/20231231_fu_nc')\n",
    "s.run_all()\n",
    "s.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to rules set by others on how to draw the flowchart, the following functions cannot be incorporated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_previous_hn(lf: pl.LazyFrame, prev_hn=prev_hn) -> pl.LazyFrame:\n",
    "    return lf.filter(~pl.col('ENC_HN').is_in(prev_hn))\n",
    "\n",
    "def print_n(df: pl.DataFrame) -> pl.DataFrame:\n",
    "        print(df['ENC_HN'].n_unique())\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2621\n"
     ]
    }
   ],
   "source": [
    "s1 = s.merged_df.pipe(clip_dates, date_col='D001KEY', start_month=7, start_year=2023, end_month=12, end_year=2023).pipe(remove_previous_hn).pipe(print_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_hn = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/AF/af_for_aj_eak_180124.csv').filter(pl.col('leg') == 'icd').to_series().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = s1.filter(pl.col('ENC_HN').is_in(icd_hn)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panda[panda[panda.columns[panda.columns.str.endswith('mg')]].notna().any(axis=1)]['ENC_HN'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n",
      "873\n",
      "28511\n"
     ]
    }
   ],
   "source": [
    "# Flow box 1\n",
    "s1 = s.merged_df.pipe(clip_dates, date_col='D001KEY', start_month=7, start_year=2023, end_month=12, end_year=2023).pipe(remove_previous_hn).pipe(print_n)\n",
    "\n",
    "# Flow box 3\n",
    "s2 = s1.pipe(remove_previous_hn).filter((pl.col('D001KEY') - pl.col('DOB')) >= pl.duration(days=365*18))\n",
    "s2.pipe(print_n)\n",
    "# Save output\n",
    "prev = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/Stroke/stroke_n_updatedSep2023_28112023.csv').pipe(parse_dates, 'Date')\n",
    "new = s2[['ENC_HN', 'D001KEY', 'D035KEY']].rename({'D001KEY': 'Date', 'D035KEY': 'ICD10'})\n",
    "output = pl.concat([new, prev])\n",
    "output.pipe(print_n)\n",
    "\n",
    "output.write_csv('D:/Prut/Warehouses/output/Dec23/n/Stroke/af_n_updated_12032024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_hn = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/AF/AF_201001_202306.csv')\n",
    "ecg_holter_hn = pl.read_csv('D:/Prut/Warehouses/output/Dec23/n/AF/df_af_use_send_CR_210324.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16/01/22'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "d = \"2022-01-16\"\n",
    "d= datetime.strftime(datetime.strptime(d, '%Y-%m-%d'), '%d/%m/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_989, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ENC_HN</th><th>Date</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1B39D7D247FAF7…</td><td>&quot;16/01/22&quot;</td></tr><tr><td>&quot;F44F7AD3764FD9…</td><td>&quot;31/08/22&quot;</td></tr><tr><td>&quot;4798862B04EA72…</td><td>&quot;22/06/21&quot;</td></tr><tr><td>&quot;FAB13CDF2898F4…</td><td>&quot;22/06/21&quot;</td></tr><tr><td>&quot;D6DCF6F5555960…</td><td>&quot;12/10/21&quot;</td></tr><tr><td>&quot;D5460D16700001…</td><td>&quot;04/02/21&quot;</td></tr><tr><td>&quot;F1F523E2DCCA5F…</td><td>&quot;31/05/21&quot;</td></tr><tr><td>&quot;78A94DE45A1987…</td><td>&quot;13/01/21&quot;</td></tr><tr><td>&quot;D85CEDCFCBA668…</td><td>&quot;13/03/21&quot;</td></tr><tr><td>&quot;F0A2E9BFFFD979…</td><td>&quot;08/09/22&quot;</td></tr><tr><td>&quot;BC895B7B874BB6…</td><td>&quot;23/03/21&quot;</td></tr><tr><td>&quot;2EBCB748312D65…</td><td>&quot;02/07/22&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;FB1B3A21602812…</td><td>&quot;05/01/23&quot;</td></tr><tr><td>&quot;FB833DDFD2E216…</td><td>&quot;18/01/23&quot;</td></tr><tr><td>&quot;FD210A3757FFF2…</td><td>&quot;28/10/22&quot;</td></tr><tr><td>&quot;FD3B632E14A2AC…</td><td>&quot;02/11/22&quot;</td></tr><tr><td>&quot;FD755C869818F5…</td><td>&quot;28/12/22&quot;</td></tr><tr><td>&quot;FE7AE0CB7C7AB0…</td><td>&quot;23/12/22&quot;</td></tr><tr><td>&quot;FEAF1D3E0C0FA2…</td><td>&quot;23/01/23&quot;</td></tr><tr><td>&quot;FF404BC7F3E74F…</td><td>&quot;30/01/23&quot;</td></tr><tr><td>&quot;FF802F7AFD6931…</td><td>&quot;19/01/23&quot;</td></tr><tr><td>&quot;FFAE555EDECBA4…</td><td>&quot;03/01/23&quot;</td></tr><tr><td>&quot;FFDE9C28B38234…</td><td>&quot;18/01/23&quot;</td></tr><tr><td>&quot;FFF042F0FA4219…</td><td>&quot;10/04/23&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_989, 2)\n",
       "┌───────────────────────────────────┬──────────┐\n",
       "│ ENC_HN                            ┆ Date     │\n",
       "│ ---                               ┆ ---      │\n",
       "│ str                               ┆ str      │\n",
       "╞═══════════════════════════════════╪══════════╡\n",
       "│ 1B39D7D247FAF7016CA1EAB23A0ED0BC… ┆ 16/01/22 │\n",
       "│ F44F7AD3764FD9233B52ED9F1F72DA49… ┆ 31/08/22 │\n",
       "│ 4798862B04EA7280B04379501F4770C1… ┆ 22/06/21 │\n",
       "│ FAB13CDF2898F415547A5A1573CE1FDD… ┆ 22/06/21 │\n",
       "│ D6DCF6F555596014FB67E8D255B93708… ┆ 12/10/21 │\n",
       "│ …                                 ┆ …        │\n",
       "│ FF404BC7F3E74F2D3032DC2A5097CF85… ┆ 30/01/23 │\n",
       "│ FF802F7AFD693178F1F43463FA6C96A7… ┆ 19/01/23 │\n",
       "│ FFAE555EDECBA4F89753DC1474DA0FBC… ┆ 03/01/23 │\n",
       "│ FFDE9C28B38234B5E9C85021116F0407… ┆ 18/01/23 │\n",
       "│ FFF042F0FA42199F43F9E873E0CF6C4E… ┆ 10/04/23 │\n",
       "└───────────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lt = prev_hn[['ENC_HN', 'Diag', 'DiagDate']]\n",
    "lt.columns = ['ENC_HN', 'how', 'Date']\n",
    "lt = lt.with_columns(pl.col('Date').map_elements(lambda x: datetime.strftime(datetime.strptime(x, '%Y-%m-%d'), '%d/%m/%y')))\n",
    "lt = lt[['ENC_HN', 'Date']]\n",
    "lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = ecg_holter_hn\n",
    "rt_drop = rt.filter(~pl.col('ENC_HN').is_in(lt.to_series().to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readme not included.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_522, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ENC_HN</th><th>how</th><th>Date</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;9D130DB828AD02…</td><td>&quot;icd&quot;</td><td>&quot;27/09/23&quot;</td></tr><tr><td>&quot;77583B105476FB…</td><td>&quot;icd&quot;</td><td>&quot;31/10/23&quot;</td></tr><tr><td>&quot;E25944D42FFCFB…</td><td>&quot;icd&quot;</td><td>&quot;12/10/23&quot;</td></tr><tr><td>&quot;FEC8F461342585…</td><td>&quot;icd&quot;</td><td>&quot;21/10/23&quot;</td></tr><tr><td>&quot;C8D2D19B630B5C…</td><td>&quot;icd&quot;</td><td>&quot;22/11/23&quot;</td></tr><tr><td>&quot;062202AD8E828E…</td><td>&quot;icd&quot;</td><td>&quot;29/09/23&quot;</td></tr><tr><td>&quot;786C8E80C82CB8…</td><td>&quot;icd&quot;</td><td>&quot;24/12/23&quot;</td></tr><tr><td>&quot;C157693532A7E9…</td><td>&quot;icd&quot;</td><td>&quot;12/10/23&quot;</td></tr><tr><td>&quot;C0566817264F1B…</td><td>&quot;icd&quot;</td><td>&quot;16/08/23&quot;</td></tr><tr><td>&quot;25A79F62B8270E…</td><td>&quot;icd&quot;</td><td>&quot;14/09/23&quot;</td></tr><tr><td>&quot;A500FE7738BD45…</td><td>&quot;icd&quot;</td><td>&quot;24/09/23&quot;</td></tr><tr><td>&quot;FA82734AE50EA2…</td><td>&quot;icd&quot;</td><td>&quot;22/12/23&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;76E997E98A2344…</td><td>&quot;icd&quot;</td><td>&quot;24/10/23&quot;</td></tr><tr><td>&quot;09AA3BA049BB18…</td><td>&quot;icd&quot;</td><td>&quot;15/11/23&quot;</td></tr><tr><td>&quot;BA411EC6483703…</td><td>&quot;icd&quot;</td><td>&quot;03/10/23&quot;</td></tr><tr><td>&quot;FC4DBFDD1D131C…</td><td>&quot;icd&quot;</td><td>&quot;18/09/23&quot;</td></tr><tr><td>&quot;6AF5BDECD5310A…</td><td>&quot;icd&quot;</td><td>&quot;20/10/23&quot;</td></tr><tr><td>&quot;68981FAEF2F3CB…</td><td>&quot;icd&quot;</td><td>&quot;02/12/23&quot;</td></tr><tr><td>&quot;52F13A5FE74A4D…</td><td>&quot;icd&quot;</td><td>&quot;10/08/23&quot;</td></tr><tr><td>&quot;316458D2C91D2D…</td><td>&quot;icd&quot;</td><td>&quot;06/10/23&quot;</td></tr><tr><td>&quot;704EE0378E6713…</td><td>&quot;icd&quot;</td><td>&quot;17/11/23&quot;</td></tr><tr><td>&quot;FBF689173F7216…</td><td>&quot;icd&quot;</td><td>&quot;08/08/23&quot;</td></tr><tr><td>&quot;E22DA32A91CE34…</td><td>&quot;icd&quot;</td><td>&quot;28/08/23&quot;</td></tr><tr><td>&quot;67E71C3A5D8F78…</td><td>&quot;icd&quot;</td><td>&quot;27/11/23&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_522, 3)\n",
       "┌───────────────────────────────────┬─────┬──────────┐\n",
       "│ ENC_HN                            ┆ how ┆ Date     │\n",
       "│ ---                               ┆ --- ┆ ---      │\n",
       "│ str                               ┆ str ┆ str      │\n",
       "╞═══════════════════════════════════╪═════╪══════════╡\n",
       "│ 9D130DB828AD02B785045E42DB815DFC… ┆ icd ┆ 27/09/23 │\n",
       "│ 77583B105476FBF8BBA8CFCC1CB8740C… ┆ icd ┆ 31/10/23 │\n",
       "│ E25944D42FFCFBC4F8B77209E3080217… ┆ icd ┆ 12/10/23 │\n",
       "│ FEC8F4613425853F5F91ACF1B56ECE40… ┆ icd ┆ 21/10/23 │\n",
       "│ C8D2D19B630B5C741658C9359B11F512… ┆ icd ┆ 22/11/23 │\n",
       "│ …                                 ┆ …   ┆ …        │\n",
       "│ 316458D2C91D2D824FACF72AC747FEBB… ┆ icd ┆ 06/10/23 │\n",
       "│ 704EE0378E6713CB758825863222EC36… ┆ icd ┆ 17/11/23 │\n",
       "│ FBF689173F7216C5903535C4C25CD78C… ┆ icd ┆ 08/08/23 │\n",
       "│ E22DA32A91CE34A968AE9802D7E3273D… ┆ icd ┆ 28/08/23 │\n",
       "│ 67E71C3A5D8F789325CA1723FF60F091… ┆ icd ┆ 27/11/23 │\n",
       "└───────────────────────────────────┴─────┴──────────┘"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icd = AFIdentify(folder='D:/Datalake/Data/20231231_fu_nc')\n",
    "icd.get_dx(select=['I48'])\n",
    "rt_icd = clip_dates(icd.dx_df, 'D001KEY', start_month=7, start_day=31, start_year=2023, end_year=2023).filter(~pl.col('ENC_HN').is_in(lt.to_series().to_list()))\n",
    "rt_icd = rt_icd.with_columns(how = pl.lit('icd')).rename({'D001KEY': 'Date'}).select(pl.col(['ENC_HN','how', 'Date'])).with_columns(pl.col('Date').map_elements(lambda x: datetime.strftime(x, '%d/%m/%y')))\n",
    "rt_icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pl.concat([rt_drop, rt_icd])\n",
    "rt = rt.group_by('ENC_HN').agg(pl.col('Date').min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (23_301, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ENC_HN</th><th>Date</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1B39D7D247FAF7…</td><td>&quot;16/01/22&quot;</td></tr><tr><td>&quot;F44F7AD3764FD9…</td><td>&quot;31/08/22&quot;</td></tr><tr><td>&quot;4798862B04EA72…</td><td>&quot;22/06/21&quot;</td></tr><tr><td>&quot;FAB13CDF2898F4…</td><td>&quot;22/06/21&quot;</td></tr><tr><td>&quot;D6DCF6F5555960…</td><td>&quot;12/10/21&quot;</td></tr><tr><td>&quot;D5460D16700001…</td><td>&quot;04/02/21&quot;</td></tr><tr><td>&quot;F1F523E2DCCA5F…</td><td>&quot;31/05/21&quot;</td></tr><tr><td>&quot;78A94DE45A1987…</td><td>&quot;13/01/21&quot;</td></tr><tr><td>&quot;D85CEDCFCBA668…</td><td>&quot;13/03/21&quot;</td></tr><tr><td>&quot;F0A2E9BFFFD979…</td><td>&quot;08/09/22&quot;</td></tr><tr><td>&quot;BC895B7B874BB6…</td><td>&quot;23/03/21&quot;</td></tr><tr><td>&quot;2EBCB748312D65…</td><td>&quot;02/07/22&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;8E16111D222CBB…</td><td>&quot;15/09/23&quot;</td></tr><tr><td>&quot;F0C97166765377…</td><td>&quot;26/09/23&quot;</td></tr><tr><td>&quot;CB8F47418CC4CF…</td><td>&quot;27/11/23&quot;</td></tr><tr><td>&quot;061F22FF89CD0B…</td><td>&quot;07/11/23&quot;</td></tr><tr><td>&quot;74A821720BE2C2…</td><td>&quot;24/12/23&quot;</td></tr><tr><td>&quot;49C572AFAA8EDC…</td><td>&quot;21/11/23&quot;</td></tr><tr><td>&quot;A69EF71EFA5049…</td><td>&quot;29/08/23&quot;</td></tr><tr><td>&quot;191BDC841DEB2C…</td><td>&quot;02/11/23&quot;</td></tr><tr><td>&quot;2FBAE46D79BBCB…</td><td>&quot;26/10/23&quot;</td></tr><tr><td>&quot;AB1593E3324EE7…</td><td>&quot;23/12/23&quot;</td></tr><tr><td>&quot;E22DA32A91CE34…</td><td>&quot;22/08/23&quot;</td></tr><tr><td>&quot;DB725BF441FCF6…</td><td>&quot;09/08/23&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (23_301, 2)\n",
       "┌───────────────────────────────────┬──────────┐\n",
       "│ ENC_HN                            ┆ Date     │\n",
       "│ ---                               ┆ ---      │\n",
       "│ str                               ┆ str      │\n",
       "╞═══════════════════════════════════╪══════════╡\n",
       "│ 1B39D7D247FAF7016CA1EAB23A0ED0BC… ┆ 16/01/22 │\n",
       "│ F44F7AD3764FD9233B52ED9F1F72DA49… ┆ 31/08/22 │\n",
       "│ 4798862B04EA7280B04379501F4770C1… ┆ 22/06/21 │\n",
       "│ FAB13CDF2898F415547A5A1573CE1FDD… ┆ 22/06/21 │\n",
       "│ D6DCF6F555596014FB67E8D255B93708… ┆ 12/10/21 │\n",
       "│ …                                 ┆ …        │\n",
       "│ 191BDC841DEB2CF66C40EF42F590D3CC… ┆ 02/11/23 │\n",
       "│ 2FBAE46D79BBCB509A5BFAE57C644582… ┆ 26/10/23 │\n",
       "│ AB1593E3324EE7805F337F6849D926AA… ┆ 23/12/23 │\n",
       "│ E22DA32A91CE34A968AE9802D7E3273D… ┆ 22/08/23 │\n",
       "│ DB725BF441FCF68D568D6AD94FD9A08A… ┆ 09/08/23 │\n",
       "└───────────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = pl.concat([lt, rt])\n",
    "assert cc.to_series().n_unique() == cc.shape[0]\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.write_csv('D:/Prut/Warehouses/output/Dec23/n/AF/af_n_21032024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
